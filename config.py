USE_LOCAL_LLM = False      # Use llama.cpp if True
USE_GPU_LLM = True         # Use GPU transformer model if True

# Switch models here easily
ACTIVE_LLM_MODEL = "microsoft/phi-1_5"
#ACTIVE_LLM_MODEL = "EleutherAI/gpt-neo-125M"

